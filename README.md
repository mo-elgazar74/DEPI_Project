# ğŸ“š Arabic Educational Chatbot - RAG Pipeline (LlamaIndex)

This project allows you to extract Arabic text from educational PDFs and ask natural language questions about them using a local RAG (Retrieval-Augmented Generation) pipeline built with **LlamaIndex**.

---

## ğŸ§± Project Structure

```
DEPI_Project/
â”œâ”€â”€ Books/
â”‚   â”œâ”€â”€ Books/                      # Raw input PDFs
â”‚   â””â”€â”€ Maths_grade_5_first_term.pdf
â”‚
â”‚
â”œâ”€â”€ index_math_g5/                 # LlamaIndex FAISS vector index (auto-generated)
â”‚   â”œâ”€â”€ docstore.json
â”‚   â”œâ”€â”€ index_store.json
â”‚   â””â”€â”€ vector_store.faiss
â”‚
â”œâ”€â”€ build_index.py                 # Builds the vector index from JSONL
â”œâ”€â”€ ask.py                         # Run this to ask questions!
â”œâ”€â”€ README.md                      # This file
â””â”€â”€ requirements.txt               # Required libraries
```

---

## âœ… 1. Prepare Your Environment (Conda Recommended) (Optional)

```bash
conda create -n edu_bot python=3.10 -y
conda activate edu_bot
pip install -r requirements.txt
```

---

## ğŸ“¥ 2. Put Your PDF(s)

Place your Arabic educational PDFs inside the folder:

```
Books/Books/
```

---

## ğŸ“¥ 3. Install Requirements

Run this in your terminal in project folder:

```
Books/Books/pip install -r requirements.txt
```

---

## ğŸ§¾ 4. Extract Text from PDF

Use the OCR extraction script (lightweight, optimized):

```bash
python extract_and_clean.py  # Or your version
```

It will generate a file like:

```
Books/Books/Maths_grade_5_first_term_clean_chunked.jsonl
```

---

## ğŸ—ï¸ 5. Build the Vector Index

```bash
python build_index.py
```

This will:
- Load the cleaned chunks
- Generate embeddings with `intfloat/multilingual-e5-small`
- Build a FAISS index
- Save everything inside `index_math_g5/`

---

## â“ 6. Ask Questions (RAG)

```bash
python ask.py
```

Then type your question in Arabic, like:

```
Question Realted to your grade ?
```

---

## ğŸ’¡ Notes

- The index is **language-aware**, so Arabic questions will work.
- No LLM (like GPT) is used by default â€” just retrieval.
- You can later plug in OpenAI, Mistral, or other models.

---

## ğŸ¤ Credits

Built with:
- LlamaIndex
- HuggingFace Embeddings
- FAISS for vector storage
# app/ask.py
import os

os.environ.setdefault("TRANSFORMERS_NO_TF", "1")
os.environ.setdefault("USE_TF", "0")
os.environ.setdefault("TF_CPP_MIN_LOG_LEVEL", "3")
os.environ.setdefault("TOKENIZERS_PARALLELISM", "false")

from pathlib import Path
from dotenv import load_dotenv

ROOT = Path(__file__).resolve().parents[1]
load_dotenv(dotenv_path=ROOT / ".env")

from llama_index.core import Settings, StorageContext, load_index_from_storage
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.vector_stores.faiss import FaissVectorStore

HAS_RERANK = False
SentenceTransformerRerank = None
try:
    from llama_index.core.postprocessor import SentenceTransformerRerank as _R  # Ø£Ø­Ø¯Ø«
    SentenceTransformerRerank = _R
    HAS_RERANK = True
except Exception:
    try:
        from llama_index.core.postprocessor import SentenceTransformerRerank as _R      # Ø£Ù‚Ø¯Ù…
        SentenceTransformerRerank = _R
        HAS_RERANK = True
    except Exception:
        print("âš ï¸ SentenceTransformerRerank ØºÙŠØ± Ù…ØªØ§Ø­: Ù‡ÙŠØ´ØªØºÙ„ Ø¨Ø¯ÙˆÙ† rerank. "
            "Ø«Ø¨Ù‘Øª: pip install -U sentence-transformers")

AR2EN = str.maketrans("Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©", "0123456789")

DEFAULT_INDEX_DIR = "/home/mohamed/DEPI_Project/Indexes/maths/g5/t1/index_math_g5_t1"
INDEX_DIR = Path(os.getenv("INDEX_DIR", str(DEFAULT_INDEX_DIR))).expanduser()

SYSTEM_PROMPT = (
    "ÙˆØ¶Ø¹ Ali5: Ø§Ø´Ø±Ø­ ÙƒØ£Ù†Ùƒ ØªØªÙƒÙ„Ù… Ù…Ø¹ Ø·ÙÙ„ Ø¹Ù…Ø±Ù‡ 5 Ø³Ù†ÙŠÙ†.\n"
    "Ø§ÙƒØªØ¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ ÙÙ‚Ø·ØŒ ÙˆÙ„Ø§ ØªØ³ØªØ®Ø¯Ù… Ø£ÙŠ ÙƒÙ„Ù…Ø§Øª Ù…Ù† Ù„ØºØ§Øª Ø£Ø®Ø±Ù‰.\n"
    "Ø§Ù„Ø£Ø³Ù„ÙˆØ¨:\n"
    "- Ø¬ÙÙ…ÙŽÙ„ Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ù‹Ø§ ÙˆÙƒÙ„Ù…Ø§Øª Ø³Ù‡Ù„Ø©.\n"
    "- Ø¹Ø±Ù‘ÙÙ Ø£ÙŠ ÙƒÙ„Ù…Ø© Ø¬Ø¯ÙŠØ¯Ø© Ø¨ÙƒÙ„Ù…ØªÙŠÙ† Ø¨Ø³ÙŠØ·ØªÙŠÙ† + Ù…Ø«Ø§Ù„ ØµØºÙŠØ±.\n"
    "- Ø§Ø³ØªØ®Ø¯Ù… ØªØ±Ù‚ÙŠÙ… ÙˆØ§Ø¶Ø­ (1ØŒ 2ØŒ 3) Ù„Ù„Ø®Ø·ÙˆØ§Øª.\n"
    "- Ù„Ùˆ Ø§Ø­ØªØ¬Øª Ù…Ø«Ø§Ù„Ù‹Ø§ØŒ Ù‚Ø¯Ù‘ÙÙ… Ù…Ø«Ø§Ù„Ù‹Ø§ Ø¨Ø³ÙŠØ·Ù‹Ø§. Ø¥Ù† Ù„Ù… ÙŠÙˆØ¬Ø¯ ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ØŒ Ù‚Ù„: (Ù…Ø«Ø§Ù„ Ù„Ù„ØªÙˆØ¶ÙŠØ­ ÙÙ‚Ø·).\n"
    "\n"
    "Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø§Ù„Ù…ØµØ§Ø¯Ø±:\n"
    "- Ø§Ø¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø©. Ø¥Ù† Ù„Ù… ØªÙƒÙÙØŒ Ù‚Ù„: (Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù…Ù† Ø§Ù„ÙƒØªØ§Ø¨).\n"
    "\n"
    "Ù„Ùˆ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø±ÙŠØ§Ø¶ÙŠØ§Øª Ø£Ùˆ ÙÙŠÙ‡ Ù…Ø¹Ø§Ø¯Ù„Ø©:\n"
    "- Ø§Ø¹Ø±Ø¶ Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø­Ù„ Ù‡ÙƒØ°Ø§:\n"
    "  1) Ù†ÙÙ‡Ù… Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ÙˆØ§Ù„Ù…Ø¹Ø·ÙŠØ§Øª.\n"
    "  2) Ù†Ø®ØªØ§Ø± Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©/Ø§Ù„ÙÙƒØ±Ø©.\n"
    "  3) Ù†Ù†ÙÙ‘Ø° Ø§Ù„Ø­Ø³Ø§Ø¨ Ø®Ø·ÙˆØ© Ø®Ø·ÙˆØ©ØŒ Ø³Ø·Ø± Ø¨Ø³Ø·Ø±.\n"
    "  4) Ù†ØªØ­Ù‚Ù‘Ù‚ Ù…Ù† Ø§Ù„Ù†ØªÙŠØ¬Ø©.\n"
    "\n"
    "ØµÙŠØºØ© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¯Ø§Ø¦Ù…Ù‹Ø§:\n"
    "- Ø§Ù„ÙÙƒØ±Ø© Ø¨Ø¨Ø³Ø§Ø·Ø©: ...\n"
    "- (Ù„Ùˆ Ø±ÙŠØ§Ø¶ÙŠØ§Øª) Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø­Ù„: 1â†’2â†’3â†’4.\n"
    "- Ù…Ø«Ø§Ù„ ØªÙˆØ¶ÙŠØ­ÙŠ: ... (Ù‚ØµÙŠØ±).\n"
)


def _normalize_base(url: str) -> str:
    if not url:
        return url
    url = url.rstrip("/")
    if url.endswith("/chat/completions"):
        url = url[: -len("/chat/completions")]
    return url

def _attach_llm():
    groq_key = os.getenv("GROQ_API_KEY")
    if not groq_key:
        Settings.llm = None
        return
    try:
        from llama_index.llms.groq import Groq
        model = os.getenv("GROQ_MODEL", "llama-3.3-70b-versatile")
        Settings.llm = Groq(model=model, api_key=groq_key, temperature=0.2)
        return
    except Exception:
        pass
    try:
        from llama_index.llms.openai_like import OpenAILike
        model = os.getenv("GROQ_MODEL", "llama-3.3-70b-versatile")
        api_base = _normalize_base(os.getenv("GROQ_API_BASE", "https://api.groq.com/openai/v1"))
        Settings.llm = OpenAILike(model=model, api_base=api_base, api_key=groq_key)
        return
    except Exception:
        Settings.llm = None

def build_query_engine(index_dir: Path, top_k: int = 4, use_rerank: bool = True):
    Settings.embed_model = HuggingFaceEmbedding(
        model_name="intfloat/multilingual-e5-small", normalize=True
    )
    _attach_llm()

    index_dir = Path(index_dir)
    vector_store = FaissVectorStore.from_persist_dir(persist_dir=str(index_dir))
    storage_ctx = StorageContext.from_defaults(persist_dir=str(index_dir),
                                                vector_store=vector_store)
    index = load_index_from_storage(storage_ctx)


    # BAAI/bge-reranker-v2-m3 (another reranker: cross-encoder/ms-marco-MiniLM-L-6-v2)
    postprocs = []
    if use_rerank and HAS_RERANK:
        postprocs.append(
            SentenceTransformerRerank(
                model="cross-encoder/ms-marco-MiniLM-L-6-v2",
                top_n=top_k,
            )
        )

    kwargs = {
        "similarity_top_k": top_k,
        "response_mode": "compact",
        "node_postprocessors": postprocs or None,
    }

    if Settings.llm is not None:
        try:
            from llama_index.core.prompts import PromptTemplate
            kwargs["text_qa_template"] = PromptTemplate(SYSTEM_PROMPT)
        except Exception:
            pass

    return index.as_query_engine(**kwargs)

def main():
    final_index = INDEX_DIR if INDEX_DIR.is_absolute() else (ROOT / INDEX_DIR)
    print(f"Using index dir: {final_index}")
    if not final_index.exists():
        print("âŒ Index dir not found. ØªØ£ÙƒØ¯ ÙˆØ¬ÙˆØ¯ default__vector_store.json Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯.")
        return

    top_k = int(os.getenv("TOP_K", "8"))
    use_rerank = os.getenv("USE_RERANK", "1") != "0"

    print("Loading index and building query engine...")
    engine = build_query_engine(final_index, top_k=top_k, use_rerank=use_rerank)

    print("ðŸ¤– Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ (Ø§ÙƒØªØ¨ q Ù„Ù„Ø®Ø±ÙˆØ¬):")
    while True:
        q = input("\nØ³Ø¤Ø§Ù„Ùƒ: ").strip()
        if not q or q.lower() == "q":
            break
        q_norm = q.translate(AR2EN)
        resp = engine.query(q_norm)

        print("\n=== Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ===")
        print(str(resp).strip())

        # Ù…ØµØ§Ø¯Ø±
        if getattr(resp, "source_nodes", None):
            print("\n--- Ù…ØµØ§Ø¯Ø± Ù…Ù† Ø§Ù„ÙƒØªØ§Ø¨ ---")
            for i, n in enumerate(resp.source_nodes, 1):
                md = n.node.metadata or {}
                page = md.get("page")
                subj = md.get("subject")
                grade = md.get("grade")
                score = getattr(n, "score", None)
                score_txt = f" | score={score:.3f}" if isinstance(score, (float, int)) else ""
                print(f"[{i}] ØµÙØ­Ø©: {page} | Ù…Ø§Ø¯Ø©: {subj} | ØµÙ: {grade}{score_txt}")
                snippet = (n.node.get_content() or "").strip().replace("\n", " ")
                if len(snippet) > 200:
                    snippet = snippet[:200] + "..."
                print(f"    {snippet}")

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
os.environ.setdefault("TRANSFORMERS_NO_TF", "1")
os.environ.setdefault("USE_TF", "0")
os.environ.setdefault("TF_CPP_MIN_LOG_LEVEL", "3")
os.environ.setdefault("TOKENIZERS_PARALLELISM", "false")

from pathlib import Path
from dotenv import load_dotenv
import re

from qdrant_client import QdrantClient
from llama_index.core import Settings
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

# ============== CONFIG ==============
ROOT = Path(__file__).resolve().parents[1]
ENV_PATH = ROOT / ".env"

TOP_K_OVERALL = 10        # Total snippets sent to LLM
TOP_K_PER_COLLECTION = 8  # Max snippets collected from each collection before merging
EMBED_MODEL_NAME = "intfloat/multilingual-e5-small"
# ====================================


# -------------------------------
# (0) Checks and cleaning rules
# -------------------------------

# is the question really a "calculation problem"?
_CALC_PAT = re.compile(r"[+\-*/Ã—Ã·%]|(?:Ù†Ø§ØªØ¬|Ø§Ø­Ø³Ø¨|ÙŠØ³Ø§ÙˆÙŠ|ÙƒÙ…\s+ÙŠØ³Ø§ÙˆÙŠ|Ù‚ÙŠÙ…Ø©|Ø­Ù„)", re.I)
def is_calc_question(q: str) -> bool:
    trans = str.maketrans("Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©", "0123456789")
    qn = (q or "").translate(trans)
    return bool(_CALC_PAT.search(qn)) and any(ch.isdigit() for ch in qn)

# Question language detection
def detect_reply_lang(s: str) -> str:
    ar = len(re.findall(r"[\u0600-\u06FF]", s or ""))
    en = len(re.findall(r"[A-Za-z]", s or ""))
    if en > ar: return "en"
    return "ar"

# Model Response Language Instruction
def lang_instruction(lang: str) -> str:
    return "Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ ÙÙ‚Ø·." if lang == "ar" else "Answer in simple English only."

# Additional cleaning: remove any numbered lists if the question is not math-related
def strip_numbering_if_not_math(answer: str, is_math: bool) -> str:
    if is_math:
        return answer
    return re.sub(r"(?m)^\s*\d+\s*[)\.\-â€“]\s*", "", answer).strip()

# TOP-K filtering by subject 
def subject_of_top_hit(hits):
    for h in sorted(hits, key=lambda x: x["score"], reverse=True):
        subj = (h.get("subject") or "").strip().lower()
        if subj:
            return subj
    return None

def filter_hits_to_subject_topk(hits, subject: str, k: int):
    if subject:
        hits = [h for h in hits if (h.get("subject") or "").strip().lower() == subject]
    return sorted(hits, key=lambda x: x["score"], reverse=True)[:k]


# -------------------------------
# (1) Prepare the LLM (Groq if available)
# -------------------------------
def load_llm():
    groq_key = os.getenv("GROQ_API_KEY")
    if not groq_key:
        return None
    try:
        from llama_index.llms.groq import Groq
        model = os.getenv("GROQ_MODEL", "llama-3.3-70b-versatile")
        llm = Groq(model=model, api_key=groq_key, temperature=0.2)
        Settings.llm = llm
        return llm
    except Exception:
        try:
            from llama_index.llms.openai_like import OpenAILike
            model = os.getenv("GROQ_MODEL", "llama-3.3-70b-versatile")
            api_base = os.getenv("GROQ_API_BASE", "https://api.groq.com/openai/v1").rstrip("/")
            llm = OpenAILike(model=model, api_base=api_base, api_key=groq_key)
            Settings.llm = llm
            return llm
        except Exception:
            return None


# -------------------------------
# (2) Qdrant helpers
# -------------------------------
def get_matching_collections(client: QdrantClient, grade: int, term: int):
    """ Returen Collections That ends with *_g{grade}_t{term} """
    suffix = f"_g{grade}_t{term}"
    cols = client.get_collections().collections
    return [c.name for c in cols if c.name.endswith(suffix)]

def search_all(client: QdrantClient, embed, collections, query: str,
               top_k_per_collection: int = TOP_K_PER_COLLECTION):
    """Pull top results from each collection, then merge and sort by score descending."""
    qvec = embed.get_query_embedding(query)
    hits = []
    for col in collections:
        try:
            res = client.query_points(
                collection_name=col,
                query=qvec,
                with_payload=True,
                limit=top_k_per_collection,
            )
            for p in res.points:
                payload = p.payload or {}
                hits.append({
                    "collection": col,
                    "score": float(p.score),
                    "text": (payload.get("text") or "").strip(),
                    "source": payload.get("source", ""),
                    "page": payload.get("page", ""),
                    "subject": payload.get("subject", ""),
                    "grade": payload.get("grade", ""),
                    "term": payload.get("term", ""),
                })
        except Exception as e:
            print(f"âš ï¸ query error in {col}: {e}")
            continue
    hits.sort(key=lambda x: x["score"], reverse=True)
    return hits


# -------------------------------
# (3) Build context and prompt
# -------------------------------
def build_context(hits, top_k_overall: int = TOP_K_OVERALL):
    chosen = hits[:top_k_overall]
    ctx_lines = []
    sources = []
    for i, h in enumerate(chosen, 1):
        snippet = (h["text"] or "").strip()
        meta = f"[{i}] src={h['source']} page={h['page']} col={h['collection']}"
        ctx_lines.append(f"{meta}\n{snippet}")
        sources.append((i, h))
    context = "\n\n".join(ctx_lines)
    return context, sources

def build_prompt(user_question: str, context: str):
    lang = detect_reply_lang(user_question)
    lang_line = lang_instruction(lang)

    SYSTEM_PROMPT = (
        "ÙˆØ¶Ø¹ Ali5: Ø§Ø´Ø±Ø­ ÙƒØ£Ù†Ùƒ ØªØªÙƒÙ„Ù… Ù…Ø¹ Ø·ÙÙ„ Ø¹Ù…Ø±Ù‡ 5 Ø³Ù†ÙŠÙ†.\n"
        "Ø£Ø¬Ø¨ Ø¨Ù„ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„ ÙƒÙ…Ø§ Ù‡ÙŠ. If the question is in English, answer in simple English.\n"
        f"{lang_line}\n"
        "Ø§Ù„Ø£Ø³Ù„ÙˆØ¨:\n"
        "- Ø¬ÙÙ…ÙÙ„ Ù…ØªÙˆØ³Ø·Ø© Ø§Ù„Ø·ÙˆÙ„ ÙˆÙƒÙ„Ù…Ø§Øª Ø³Ù‡Ù„Ø©.\n"
        "- Ø¹Ø±Ù‘ÙÙ Ø£ÙŠ ÙƒÙ„Ù…Ø© Ø¬Ø¯ÙŠØ¯Ø© Ø¨ÙƒÙ„Ù…ØªÙŠÙ† Ø¨Ø³ÙŠØ·ØªÙŠÙ† + Ù…Ø«Ø§Ù„ ØµØºÙŠØ± (Ø¥Ù† Ù„Ø²Ù…). Ø¥Ù† Ù„Ù… ÙŠÙˆØ¬Ø¯ Ù…Ø«Ø§Ù„ Ù…Ù† Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ØŒ Ø§ÙƒØªØ¨: (Ù…Ø«Ø§Ù„ Ù„Ù„ØªÙˆØ¶ÙŠØ­ ÙÙ‚Ø·).\n"
        "- Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… ØªØ¹Ø¯Ø§Ø¯Ù‹Ø§ Ø¨Ø§Ù„Ø£Ø±Ù‚Ø§Ù… (1ØŒ 2ØŒ 3) Ø¥Ù„Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ø³Ø£Ù„Ø© Ø­Ø³Ø§Ø¨ÙŠØ© ÙÙŠÙ‡Ø§ Ø¹Ù…Ù„ÙŠØ§Øª (+ âˆ’ Ã— Ã· %).\n"
        "\n"
        "Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø§Ù„Ù…ØµØ§Ø¯Ø±:\n"
        "- Ø§Ø¹ØªÙ…Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ù…Ø±ÙÙ‚Ø©. Ø¥Ù† Ù„Ù… ØªÙƒÙÙØŒ Ø§ÙƒØªØ¨: (Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù…Ù† Ø§Ù„ÙƒØªØ§Ø¨).\n"
        "\n"
        "Ù„Ùˆ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ø³Ø£Ù„Ø© Ø­Ø³Ø§Ø¨ÙŠØ©:\n"
        "  1) Ù†ÙÙ‡Ù… Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ÙˆØ§Ù„Ù…Ø¹Ø·ÙŠØ§Øª.\n"
        "  2) Ù†Ø®ØªØ§Ø± Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©.\n"
        "  3) Ù†Ù†ÙÙ‘Ø° Ø§Ù„Ø­Ø³Ø§Ø¨ Ø®Ø·ÙˆØ© Ø®Ø·ÙˆØ© Ø¨Ø§Ø®ØªØµØ§Ø±.\n"
        "  4) Ù†ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†ØªÙŠØ¬Ø©.\n"
    )

    return (
        f"{SYSTEM_PROMPT}\n\n"
        f"Ø§Ù„Ø³Ø¤Ø§Ù„:\n{user_question}\n\n"
        f"Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø©:\n{context}\n\n"
        f"Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ ÙÙ‚Ø·."
    )

def print_sources(sources):
    print("\n--- Ù…ØµØ§Ø¯Ø± Ù…Ù† Ø§Ù„ÙƒØªØ§Ø¨ ---")
    for i, h in sources:
        score = h["score"]
        src = h["source"]; page = h["page"]; col = h["collection"]
        print(f"[{i}] score={score:.4f} | src={src} | page={page} | col={col}")
        # print("    " + h["text"].replace("\n", " ") + "\n")

# -------------------------------
# (4) Deployment
# -------------------------------
def main():
    # 1) Env & clients
    load_dotenv(ENV_PATH)
    url = os.getenv("URL_QDRANT"); key = os.getenv("API_KEY_QDRANT")
    if not url or not key:
        raise EnvironmentError("âŒ Ø¶Ø¹ URL_QDRANT Ùˆ API_KEY_QDRANT ÙÙŠ .env")

    client = QdrantClient(url=url, api_key=key)
    embed = HuggingFaceEmbedding(model_name=EMBED_MODEL_NAME, normalize=True)
    llm = load_llm()  # Ù…Ù…ÙƒÙ† ÙŠÙƒÙˆÙ† None

    # 2) Enter grade & term
    print("Ø§Ø¯Ø®Ù„ Ø§Ù„ØµÙ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠ ÙˆØ§Ù„ØªØ±Ù… Ù„Ù„Ø¨Ø­Ø«:")
    while True:
        try:
            grade = int(input("enter grade (1 to 6): ").strip())
            if grade not in (1,2,3,4,5,6): raise ValueError
            break
        except Exception:
            print("âš ï¸ Ù…Ù† 1 Ù„Ù€ 6 ÙÙ‚Ø·.")
    while True:
        try:
            term = int(input("enter term (1 or 2): ").strip())
            if term not in (1,2): raise ValueError
            break
        except Exception:
            print("âš ï¸ Ø§Ø®ØªÙØ± 1 Ø£Ùˆ 2.")

    # 3) Get collections for that grade & term
    collections = get_matching_collections(client, grade, term)
    if not collections:
        print(f"âŒ No Collections that ends with _g{grade}_t{term}")
        return
    print("Selected Collections:", ", ".join(collections))

    # 4) Ask
    print("\nğŸ¤– Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ (q Ù„Ù„Ø®Ø±ÙˆØ¬):")
    while True:
        q = input("\nØ³Ø¤Ø§Ù„Ùƒ: ").strip()
        if not q or q.lower() == "q":
            break

        # Initial search From All Collections
        hits = search_all(client, embed, collections, q, TOP_K_PER_COLLECTION)
        if not hits:
            print("âš ï¸ No Matching Results.")
            continue

        # Get Top-K from Dominant Subject
        dom_subj = subject_of_top_hit(hits)
        hits = filter_hits_to_subject_topk(hits, dom_subj, k=TOP_K_OVERALL)

        # Build context from filtered snippets
        context, sources = build_context(hits, TOP_K_OVERALL)

        # If no LLM â†’ print top snippets only
        if llm is None:
            print("\n=== Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Ø¨Ø¯ÙˆÙ† ØªÙˆÙ„ÙŠØ¯) ===")
            for i, h in sources:
                txt = h["text"].replace("\n", " ")
                print(f"[{i}] score={h['score']:.4f} | src={h['source']} | page={h['page']} | col={h['collection']}")
                print(f"    {txt[:200]}\n")
            continue

        # With LLM â†’ build prompt & generate answer
        prompt = build_prompt(q, context)
        try:
            answer = llm.complete(prompt).text
            # Delete any numbered lists if the question is not math-related
            answer = strip_numbering_if_not_math(answer, is_calc_question(q))
        except Exception as e:
            print(f"âš ï¸ LLM error: {e}")
            # fallback : Print top snippets
            print("\n=== Top Snippets ===")
            for i, h in sources:
                txt = h["text"].replace("\n", " ")
                print(f"[{i}] score={h['score']:.4f} | src={h['source']} | page={h['page']} | col={h['collection']}")
                print(f"    {txt[:200]}\n")
            continue

        print("\n=== Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ===")
        print(answer.strip())
        print_sources(sources)


if __name__ == "__main__":
    main()
